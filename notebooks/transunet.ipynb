{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00be7b96-6314-423c-aa28-aeda3919b56c",
   "metadata": {},
   "source": [
    "# Investigating TransUNet\n",
    "\n",
    "TransUNet is a version of unet that utilizes transformers during the encoding stage.  Details of the model can be read in the paper [3D TransUNet: Advancing Medical Image Segmentation through Vision Transformers](https://arxiv.org/abs/2310.07781) This model caught my attention because of it's use of transformers and the emphasized usecase of medical image segmentation.\n",
    "\n",
    "The writers were kind enough to publish a git repo with their code, and another good samaritan made a [Tensorflow version](https://github.com/awsaf49/TransUNet-tf).  I'm more comfortable with tensorflow, so I'll try that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0ad80d-8e1b-4a8d-a2cb-f480e82515a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Motoko\\miniconda3\\envs\\.myenv\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transunet import TransUNet\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b780b924-c7c7-4f15-adcd-ca60136920c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 16s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/vit_models/imagenet21k/R50+ViT-B_16.npz\n",
      "461217452/461217452 [==============================] - 74s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = TransUNet(image_size=224, pretrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d0ad8-b8f3-47f5-b428-de43298825ca",
   "metadata": {},
   "source": [
    "The download details note that the model is using resnet50v2 and R50+ViT-B_16, pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2735148-21e3-4c46-8f3e-0b26a58d9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not particularly interested in downloading the weights everytime\n",
    "# I load the model, so I'll save it locally in .keras format.\n",
    "dst = 'D:/Downloads/models/tunet-pretrained.keras'\n",
    "model.save(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197cae1-eb8e-4d8e-89f8-c7ff1212a5cb",
   "metadata": {},
   "source": [
    "## Examine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1493fe-7846-48fd-b926-98604e7b8b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TransUNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (Ba  (None, 56, 56, 64)           256       ['pool1_pool[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (  (None, 56, 56, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4096      ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
      "                                                                     'conv2_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 28, 28, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 28, 28, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 28, 28, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 256)          0         ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 28, 28, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)      (None, 28, 28, 256)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (Ba  (None, 28, 28, 256)          1024      ['conv2_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (  (None, 28, 28, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32768     ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
      "                                                                     'conv3_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 14, 14, 128)          147456    ['conv3_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 14, 14, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 14, 14, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 512)          0         ['conv3_block3_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 14, 14, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)      (None, 14, 14, 512)          0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'conv3_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (Ba  (None, 14, 14, 512)          2048      ['conv3_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (  (None, 14, 14, 512)          0         ['conv4_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131072    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_conv[0][0]', \n",
      "                                                                     'conv4_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block5_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block5_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block5_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block5_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block5_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block6_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " embedding (Conv2D)          (None, 14, 14, 768)          787200    ['conv4_block6_preact_relu[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 196, 768)             0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " Transformer/posembed_input  (None, 196, 768)             150528    ['reshape[0][0]']             \n",
      "  (AddPositionEmbs)                                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 196, 768)             0         ['Transformer/posembed_input[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_0  ((None, 196, 768),           7087872   ['dropout[0][0]']             \n",
      "  (TransformerBlock)          (None, 12, None, None))                                             \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_1  ((None, 196, 768),           7087872   ['Transformer/encoderblock_0[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_2  ((None, 196, 768),           7087872   ['Transformer/encoderblock_1[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_3  ((None, 196, 768),           7087872   ['Transformer/encoderblock_2[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_4  ((None, 196, 768),           7087872   ['Transformer/encoderblock_3[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_5  ((None, 196, 768),           7087872   ['Transformer/encoderblock_4[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_6  ((None, 196, 768),           7087872   ['Transformer/encoderblock_5[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_7  ((None, 196, 768),           7087872   ['Transformer/encoderblock_6[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_8  ((None, 196, 768),           7087872   ['Transformer/encoderblock_7[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_9  ((None, 196, 768),           7087872   ['Transformer/encoderblock_8[0\n",
      "  (TransformerBlock)          (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_1  ((None, 196, 768),           7087872   ['Transformer/encoderblock_9[0\n",
      " 0 (TransformerBlock)         (None, 12, None, None))               ][0]']                        \n",
      "                                                                                                  \n",
      " Transformer/encoderblock_1  ((None, 196, 768),           7087872   ['Transformer/encoderblock_10[\n",
      " 1 (TransformerBlock)         (None, 12, None, None))               0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer/encoder_norm (  (None, 196, 768)             1536      ['Transformer/encoderblock_11[\n",
      " LayerNormalization)                                                0][0]']                       \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 14, 14, 768)          0         ['Transformer/encoder_norm[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " decoder_cup (DecoderCup)    (None, 224, 224, 16)         7390080   ['reshape_1[0][0]',           \n",
      "                                                                     'conv3_block4_preact_relu[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'conv2_block3_preact_relu[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " seg_head (SegmentationHead  (None, 224, 224, 3)          51        ['decoder_cup[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100840115 (384.67 MB)\n",
      "Trainable params: 93380979 (356.22 MB)\n",
      "Non-trainable params: 7459136 (28.45 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32412cbe-5dd5-4dd1-a3f5-4ca2c81a45ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 0: input_2 -- trainable: False\n",
      "LAYER 1: conv1_pad -- trainable: False\n",
      "LAYER 2: conv1_conv -- trainable: False\n",
      "LAYER 3: pool1_pad -- trainable: False\n",
      "LAYER 4: pool1_pool -- trainable: False\n",
      "LAYER 5: conv2_block1_preact_bn -- trainable: False\n",
      "LAYER 6: conv2_block1_preact_relu -- trainable: False\n",
      "LAYER 7: conv2_block1_1_conv -- trainable: False\n",
      "LAYER 8: conv2_block1_1_bn -- trainable: False\n",
      "LAYER 9: conv2_block1_1_relu -- trainable: False\n",
      "LAYER 10: conv2_block1_2_pad -- trainable: False\n",
      "LAYER 11: conv2_block1_2_conv -- trainable: False\n",
      "LAYER 12: conv2_block1_2_bn -- trainable: False\n",
      "LAYER 13: conv2_block1_2_relu -- trainable: False\n",
      "LAYER 14: conv2_block1_0_conv -- trainable: False\n",
      "LAYER 15: conv2_block1_3_conv -- trainable: False\n",
      "LAYER 16: conv2_block1_out -- trainable: False\n",
      "LAYER 17: conv2_block2_preact_bn -- trainable: False\n",
      "LAYER 18: conv2_block2_preact_relu -- trainable: False\n",
      "LAYER 19: conv2_block2_1_conv -- trainable: False\n",
      "LAYER 20: conv2_block2_1_bn -- trainable: False\n",
      "LAYER 21: conv2_block2_1_relu -- trainable: False\n",
      "LAYER 22: conv2_block2_2_pad -- trainable: False\n",
      "LAYER 23: conv2_block2_2_conv -- trainable: False\n",
      "LAYER 24: conv2_block2_2_bn -- trainable: False\n",
      "LAYER 25: conv2_block2_2_relu -- trainable: False\n",
      "LAYER 26: conv2_block2_3_conv -- trainable: False\n",
      "LAYER 27: conv2_block2_out -- trainable: False\n",
      "LAYER 28: conv2_block3_preact_bn -- trainable: False\n",
      "LAYER 29: conv2_block3_preact_relu -- trainable: False\n",
      "LAYER 30: conv2_block3_1_conv -- trainable: False\n",
      "LAYER 31: conv2_block3_1_bn -- trainable: False\n",
      "LAYER 32: conv2_block3_1_relu -- trainable: False\n",
      "LAYER 33: conv2_block3_2_pad -- trainable: False\n",
      "LAYER 34: conv2_block3_2_conv -- trainable: False\n",
      "LAYER 35: conv2_block3_2_bn -- trainable: False\n",
      "LAYER 36: conv2_block3_2_relu -- trainable: False\n",
      "LAYER 37: max_pooling2d -- trainable: False\n",
      "LAYER 38: conv2_block3_3_conv -- trainable: False\n",
      "LAYER 39: conv2_block3_out -- trainable: False\n",
      "LAYER 40: conv3_block1_preact_bn -- trainable: False\n",
      "LAYER 41: conv3_block1_preact_relu -- trainable: False\n",
      "LAYER 42: conv3_block1_1_conv -- trainable: False\n",
      "LAYER 43: conv3_block1_1_bn -- trainable: False\n",
      "LAYER 44: conv3_block1_1_relu -- trainable: False\n",
      "LAYER 45: conv3_block1_2_pad -- trainable: False\n",
      "LAYER 46: conv3_block1_2_conv -- trainable: False\n",
      "LAYER 47: conv3_block1_2_bn -- trainable: False\n",
      "LAYER 48: conv3_block1_2_relu -- trainable: False\n",
      "LAYER 49: conv3_block1_0_conv -- trainable: False\n",
      "LAYER 50: conv3_block1_3_conv -- trainable: False\n",
      "LAYER 51: conv3_block1_out -- trainable: False\n",
      "LAYER 52: conv3_block2_preact_bn -- trainable: False\n",
      "LAYER 53: conv3_block2_preact_relu -- trainable: False\n",
      "LAYER 54: conv3_block2_1_conv -- trainable: False\n",
      "LAYER 55: conv3_block2_1_bn -- trainable: False\n",
      "LAYER 56: conv3_block2_1_relu -- trainable: False\n",
      "LAYER 57: conv3_block2_2_pad -- trainable: False\n",
      "LAYER 58: conv3_block2_2_conv -- trainable: False\n",
      "LAYER 59: conv3_block2_2_bn -- trainable: False\n",
      "LAYER 60: conv3_block2_2_relu -- trainable: False\n",
      "LAYER 61: conv3_block2_3_conv -- trainable: False\n",
      "LAYER 62: conv3_block2_out -- trainable: False\n",
      "LAYER 63: conv3_block3_preact_bn -- trainable: False\n",
      "LAYER 64: conv3_block3_preact_relu -- trainable: False\n",
      "LAYER 65: conv3_block3_1_conv -- trainable: False\n",
      "LAYER 66: conv3_block3_1_bn -- trainable: False\n",
      "LAYER 67: conv3_block3_1_relu -- trainable: False\n",
      "LAYER 68: conv3_block3_2_pad -- trainable: False\n",
      "LAYER 69: conv3_block3_2_conv -- trainable: False\n",
      "LAYER 70: conv3_block3_2_bn -- trainable: False\n",
      "LAYER 71: conv3_block3_2_relu -- trainable: False\n",
      "LAYER 72: conv3_block3_3_conv -- trainable: False\n",
      "LAYER 73: conv3_block3_out -- trainable: False\n",
      "LAYER 74: conv3_block4_preact_bn -- trainable: False\n",
      "LAYER 75: conv3_block4_preact_relu -- trainable: False\n",
      "LAYER 76: conv3_block4_1_conv -- trainable: False\n",
      "LAYER 77: conv3_block4_1_bn -- trainable: False\n",
      "LAYER 78: conv3_block4_1_relu -- trainable: False\n",
      "LAYER 79: conv3_block4_2_pad -- trainable: False\n",
      "LAYER 80: conv3_block4_2_conv -- trainable: False\n",
      "LAYER 81: conv3_block4_2_bn -- trainable: False\n",
      "LAYER 82: conv3_block4_2_relu -- trainable: False\n",
      "LAYER 83: max_pooling2d_1 -- trainable: False\n",
      "LAYER 84: conv3_block4_3_conv -- trainable: False\n",
      "LAYER 85: conv3_block4_out -- trainable: False\n",
      "LAYER 86: conv4_block1_preact_bn -- trainable: False\n",
      "LAYER 87: conv4_block1_preact_relu -- trainable: False\n",
      "LAYER 88: conv4_block1_1_conv -- trainable: False\n",
      "LAYER 89: conv4_block1_1_bn -- trainable: False\n",
      "LAYER 90: conv4_block1_1_relu -- trainable: False\n",
      "LAYER 91: conv4_block1_2_pad -- trainable: False\n",
      "LAYER 92: conv4_block1_2_conv -- trainable: False\n",
      "LAYER 93: conv4_block1_2_bn -- trainable: False\n",
      "LAYER 94: conv4_block1_2_relu -- trainable: False\n",
      "LAYER 95: conv4_block1_0_conv -- trainable: False\n",
      "LAYER 96: conv4_block1_3_conv -- trainable: False\n",
      "LAYER 97: conv4_block1_out -- trainable: False\n",
      "LAYER 98: conv4_block2_preact_bn -- trainable: False\n",
      "LAYER 99: conv4_block2_preact_relu -- trainable: False\n",
      "LAYER 100: conv4_block2_1_conv -- trainable: False\n",
      "LAYER 101: conv4_block2_1_bn -- trainable: False\n",
      "LAYER 102: conv4_block2_1_relu -- trainable: False\n",
      "LAYER 103: conv4_block2_2_pad -- trainable: False\n",
      "LAYER 104: conv4_block2_2_conv -- trainable: False\n",
      "LAYER 105: conv4_block2_2_bn -- trainable: False\n",
      "LAYER 106: conv4_block2_2_relu -- trainable: False\n",
      "LAYER 107: conv4_block2_3_conv -- trainable: False\n",
      "LAYER 108: conv4_block2_out -- trainable: False\n",
      "LAYER 109: conv4_block3_preact_bn -- trainable: False\n",
      "LAYER 110: conv4_block3_preact_relu -- trainable: False\n",
      "LAYER 111: conv4_block3_1_conv -- trainable: False\n",
      "LAYER 112: conv4_block3_1_bn -- trainable: False\n",
      "LAYER 113: conv4_block3_1_relu -- trainable: False\n",
      "LAYER 114: conv4_block3_2_pad -- trainable: False\n",
      "LAYER 115: conv4_block3_2_conv -- trainable: False\n",
      "LAYER 116: conv4_block3_2_bn -- trainable: False\n",
      "LAYER 117: conv4_block3_2_relu -- trainable: False\n",
      "LAYER 118: conv4_block3_3_conv -- trainable: False\n",
      "LAYER 119: conv4_block3_out -- trainable: False\n",
      "LAYER 120: conv4_block4_preact_bn -- trainable: False\n",
      "LAYER 121: conv4_block4_preact_relu -- trainable: False\n",
      "LAYER 122: conv4_block4_1_conv -- trainable: False\n",
      "LAYER 123: conv4_block4_1_bn -- trainable: False\n",
      "LAYER 124: conv4_block4_1_relu -- trainable: False\n",
      "LAYER 125: conv4_block4_2_pad -- trainable: False\n",
      "LAYER 126: conv4_block4_2_conv -- trainable: False\n",
      "LAYER 127: conv4_block4_2_bn -- trainable: False\n",
      "LAYER 128: conv4_block4_2_relu -- trainable: False\n",
      "LAYER 129: conv4_block4_3_conv -- trainable: False\n",
      "LAYER 130: conv4_block4_out -- trainable: False\n",
      "LAYER 131: conv4_block5_preact_bn -- trainable: False\n",
      "LAYER 132: conv4_block5_preact_relu -- trainable: False\n",
      "LAYER 133: conv4_block5_1_conv -- trainable: False\n",
      "LAYER 134: conv4_block5_1_bn -- trainable: False\n",
      "LAYER 135: conv4_block5_1_relu -- trainable: False\n",
      "LAYER 136: conv4_block5_2_pad -- trainable: False\n",
      "LAYER 137: conv4_block5_2_conv -- trainable: False\n",
      "LAYER 138: conv4_block5_2_bn -- trainable: False\n",
      "LAYER 139: conv4_block5_2_relu -- trainable: False\n",
      "LAYER 140: conv4_block5_3_conv -- trainable: False\n",
      "LAYER 141: conv4_block5_out -- trainable: False\n",
      "LAYER 142: conv4_block6_preact_bn -- trainable: False\n",
      "LAYER 143: conv4_block6_preact_relu -- trainable: False\n",
      "LAYER 144: embedding -- trainable: True\n",
      "LAYER 145: reshape -- trainable: True\n",
      "LAYER 146: Transformer/posembed_input -- trainable: True\n",
      "LAYER 147: dropout -- trainable: True\n",
      "LAYER 148: Transformer/encoderblock_0 -- trainable: True\n",
      "LAYER 149: Transformer/encoderblock_1 -- trainable: True\n",
      "LAYER 150: Transformer/encoderblock_2 -- trainable: True\n",
      "LAYER 151: Transformer/encoderblock_3 -- trainable: True\n",
      "LAYER 152: Transformer/encoderblock_4 -- trainable: True\n",
      "LAYER 153: Transformer/encoderblock_5 -- trainable: True\n",
      "LAYER 154: Transformer/encoderblock_6 -- trainable: True\n",
      "LAYER 155: Transformer/encoderblock_7 -- trainable: True\n",
      "LAYER 156: Transformer/encoderblock_8 -- trainable: True\n",
      "LAYER 157: Transformer/encoderblock_9 -- trainable: True\n",
      "LAYER 158: Transformer/encoderblock_10 -- trainable: True\n",
      "LAYER 159: Transformer/encoderblock_11 -- trainable: True\n",
      "LAYER 160: Transformer/encoder_norm -- trainable: True\n",
      "LAYER 161: reshape_1 -- trainable: True\n",
      "LAYER 162: decoder_cup -- trainable: True\n",
      "LAYER 163: seg_head -- trainable: True\n"
     ]
    }
   ],
   "source": [
    "# Printing out each layer name, number, and whether or not it's trainable.\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    conf = layer.get_config()\n",
    "    name = conf.pop('name')\n",
    "\n",
    "    print(f'''LAYER {i}: {name} -- trainable: {layer.trainable}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4848a653-a117-4b99-bb8e-974677af7676",
   "metadata": {},
   "source": [
    "So we have 164 layers.  The first 144 are frozen, which is great because our dataset is invariably going to be too small and we don't want to overfit, while the final 20 layers are unfrozen.  I think that might still be too much, but we can play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53986200-1e63-4532-8ef8-8840cc1b6b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Speaking of, can tensorflow see my GPU?\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f15b68-2ff8-4620-b733-bfd04f790d76",
   "metadata": {},
   "source": [
    "## @#$%!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed842cc-a955-4952-9e6a-4958338f11d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
